# Libs
import cv2
import os
import dlib
import bpy
import matplotlib
import math, random
from mathutils import *
matplotlib.use('agg')
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation
import pandas as pd
import numpy as np
import pprint

'''Possibly the holy grail'''
'''https://www.programcreek.com/python/example/89450/cv2.Rodrigues'''
############################# Variables #############################

# Camera
cap = cv2.VideoCapture(0)

# face detector
detector = dlib.get_frontal_face_detector()

# landmark predictor
predictor = dlib.shape_predictor("C:/Users/tonym/OneDrive/AAM_Portfolio/client_projects/objectManipulation/landmarks/shape_predictor_68_face_landmarks.dat")

# font for landmark label
font = cv2.FONT_HERSHEY_SIMPLEX

# Bools
cmra = True
save = False
visu = True
motion = False

# Landmark List
FACIAL_LANDMARKS_IDXS = [
    ("mouth", (48, 68)),
    ("right_eyebrow", (17, 22)),
    ("left_eyebrow", (22, 27)),
    ("right_eye", (36, 42)),
    ("left_eye", (42, 48)),
    ("nose", (27, 35)),
    ("jaw", (0, 17))
]

# Landmark List (Subset for Performance)
lm_groups = [
    ("mouth", (50,52,58,56,60,64)),
    ("right_eyebrow", (18,20)),
    ("left_eyebrow", (22,24)),
    ("right_eye", (38,40)),
    ("left_eye", (44,48)),
    ("nose", (30,32,34,36)),
    ("jaw", (2,7,11,16))
]

sub = list()

for l in lm_groups:
    sub+=l[1]

_lm = set(sub)

# Neck Bone for head rotation
neck_bone = ["cSpine"]

# testing focus
_lm = lm_groups[0][1]

# Full LandMark Range
lm_full = set(list(range(0,68)))

# data printer
p = pprint.PrettyPrinter(indent=1, width=80, depth=None, stream=None, compact=False)

# print the algorithm landmark setup
print("The full set of landmarks are:", lm_full)
print("The landmarks included in app:", _lm)
print("Landmark areas include:")
p.pprint(lm_groups)


############################# Definitions #############################

# change mode
def setMode(newMode):
    bpy.ops.object.mode_set(mode=newMode) 
    return True

# translate bone
def translateBoneXYZ( armatureName, modeName, boneName, x_offset, y_offset, z_offset=0 ):

    # Get Armature
    arm = bpy.data.objects[armatureName]
    
    # POSE mode allows translation
    setMode(modeName)                      
    
    # Get Bone
    targetBone = arm.pose.bones[boneName]  
    
    targetBone.bone.select=True
    # targetBone.bone.select_tail=True
    # targetBone.bone.select_head=True       # Make Bone Cursor Focus
    
    # Translate Bone
    bpy.ops.transform.translate(           # Translate Bone
        value=(x_offset, y_offset, z_offset), 
        orient_type='GLOBAL', 
        orient_matrix=((1, 0, 0), (0, 1, 0), (0, 0, 1)), 
        orient_matrix_type='GLOBAL', 
        mirror=True, 
        use_proportional_edit=False, 
        proportional_edit_falloff='SMOOTH', 
        proportional_size=1, 
        use_proportional_connected=False, 
        use_proportional_projected=False, 
        release_confirm=True
    )
    
    # Redraw the 3d view
    bpy.ops.wm.redraw_timer(type='DRAW_WIN_SWAP', iterations=1) # Refresh 3D View
    
    # targetBone.bone.select=False

    return True
  
# change bone location
def positionBoneXYZ( armatureName, modeName, x, y, z=0 ):
    scene = bpy.context.scene

    arm = scene.objects[armatureName]
    avatar = scene.objects["male head.obj"]
    cam = scene.objects["Camera"]

    arm = bpy.data.objects[armatureName]            # Get Armature
    setMode("POSE")                                 # need POSE mode to set armature bones

    for i in range(min(_lm), max(_lm)+1): 
        targetBone = arm.pose.bones["Bone."+str(i)]
        pb.location[0] = x
        pb.location[2] = y

    return True

# captures current scene as matrix
def return_frame():

    # capture scene as a matrix as output 
    scn = bpy.context.scene

    # go to frame f
    scn.frame_set(0)
    
    if save:
        # set the filepath
        scn.render.filepath = os.path.join('C:/Users/tonym/OneDrive/AAM_Portfolio/client_projects/MIMIC/AugmentedReality/demoFace/', str(f).zfill(4))

        # render the current frame
        bpy.ops.render.render(write_still=True)

    # output the camera matrix on the current frame        
    return scn.camera.matrix_world


# loops over camera frames, move's bones ( animates face ), and captures the new frame
def animate(cycles):
    
    # Mode Name
    mode = "POSE"

    # Armature Name
    armature = "Armature.face"
    
    # Counter
    counter = 0
    
    # motion window
    wind = []
    
    # loop
    while counter < cycles:    
        # get frame
        _, frame = cap.read()

        # get grey frame
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # detect faces
        faces = detector(gray)
    
        # loop through faces   
        for face in faces:
            
            # Position of Face
            x1 = face.left()
            y1 = face.top()
            x2 = face.right()
            y2 = face.bottom()
            
            # Face Position Information
            info = "Frame:"+str(counter)+" x1:"+str(x1)+" y1:"+str(y1)+" x2:"+str(x2)+" y2:"+str(y2)
            
            # Draw face Bounding Box
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
            cv2.putText(frame, info, (x1,y1), font, .25, (255, 0, 0), 1, cv2.LINE_AA)
            
            # get all landmarks for face i
            landmarks = predictor(gray, face)
            
            # get angles of head pose [rotation and translation vectors]
            img, rot, tra = headPoseEstimation(frame, landmarks)
            
            rotateBoneEuler( armatureName="Armature.neck", modeName="POSE", boneName="cSpine", rotation_vector=[rot[1][0],rot[2][0]] )            
            
            # to move the Face Armature
            if motion:            
                # initialize
                if counter == 0:
                    for n in range(min(_lm), max(_lm)+1):
                        if n in _lm:
                            x = landmarks.part(n).x
                            y = landmarks.part(n).y
                            wind.append({"markerNumber": n, "xPos": x, "yPos": y})
                        else:
                            pass
                        
                # provide motion change
                if counter != 0:
                    plcmnt=1
                    for n in range(min(_lm), max(_lm)+1):
                        if n in _lm:
                            item = list(filter(lambda marker: marker['markerNumber'] == n, wind))[0]
                            x = landmarks.part(n).x
                            y = landmarks.part(n).y
                            x_old = item["xPos"]
                            y_old = item["yPos"]
                            x_delta = x_old - x
                            y_delta = y_old - y
                            item["xPos"] = x
                            item["yPos"] = y            
                            cv2.circle(frame, (x, y), 4, (255, n*3, n*2), -1)
                            info = "n:"+str(n)+" x:"+str(x)+" y:"+str(y)
                            cv2.putText(frame, info, (10, 10*plcmnt), font, .25, (255, n*3, n*2), 1, cv2.LINE_AA)
                            plcmnt+=1
                            cv2.putText(frame, str(n), (x+5, y), font, .5, (255, n*3, n*2), 1, cv2.LINE_AA)
                            #translateBoneXYZ( armatureName=armature, modeName=mode, boneName="Bone."+str(n), x_offset=x_delta/50, y_offset=y_delta/50, z_offset=0.00 )
                        else:
                            pass                        
                p.pprint(wind)

        if visu:
                        
            # display image with opencv or any operation you like
            frame = cv2.resize(frame, (frame.shape[1]*3, frame.shape[0]*3))
            cv2.imshow("Frame", frame)

            key = cv2.waitKey(1)
            if key == 27:
                break
            
        counter+=1
    

def rotateBoneEuler( armatureName, modeName, boneName, rotation_vector ):
    
    # Get Armature
    arm = bpy.data.objects[armatureName]
    
    # POSE mode allows translation
    setMode(modeName)                      
    
    # Get Bone
    targetBone = arm.pose.bones[boneName]  

    # Select Bone
    targetBone.bone.select=True 

    bpy.ops.transform.trackball(
        value=rotation_vector, #[3.14,3.14]
        mirror=True, 
        use_proportional_edit=False, 
        proportional_edit_falloff='SMOOTH', 
        proportional_size=1, 
        use_proportional_connected=False, 
        use_proportional_projected=False, 
        release_confirm=True
    )
        
    # Redraw the 3d view
    bpy.ops.wm.redraw_timer(type='DRAW_WIN_SWAP', iterations=1) # Refresh 3D View
    
    ''' bpy.ops.transform.rotate(
        value=y_degrees, 
        orient_axis='Y', 
        orient_type='GLOBAL', 
        orient_matrix=((1, 0, 0), (0, 1, 0), (0, 0, 1)), 
        orient_matrix_type='GLOBAL', 
        constraint_axis=(False, True, False), 
        mirror=True, 
        use_proportional_edit=False, 
        proportional_edit_falloff='SMOOTH', 
        proportional_size=1, 
        use_proportional_connected=False, 
        use_proportional_projected=False, 
        release_confirm=True
        )
        '''
    print("Rotated", boneName)
    # Set rotation mode to Euler XYZ, easier to understand
    #targetBone.rotation_mode = 'XYZ'
    
    # Euler features
    #euler = ['X','Y','Z']
    # select axis in ['X','Y','Z']  <--bone local
    #for axis in euler:
    #    angle = 90
    #    targetBone.rotation_euler.rotate_axis(axis, math.radians(angle))
    
    return True 

def return_roll_pitch_yaw(image, radians=False):
     """ Return the the roll pitch and yaw angles associated with the input image.
 
     @param image It is a colour image. It must be >= 64 pixel.
     @param radians When True it returns the angle in radians, otherwise in degrees.
     """
     
     # The dlib shape predictor returns 68 points, we are interested only in a few of those
     # TRACKED_POINTS = (0, 4, 8, 12, 16, 17, 26, 27, 30, 33, 36, 39, 42, 45, 62)
 
     # Antropometric constant values of the human head. 
     # Check the wikipedia EN page and:
     # "Head-and-Face Anthropometric Survey of U.S. Respirator Users"
     #
     # X-Y-Z with X pointing forward and Y on the left and Z up.
     # The X-Y-Z coordinates used are like the standard
     # coordinates of ROS (robotic operative system)
     # OpenCV uses the reference usually used in computer vision: 
     # X points to the right, Y down, Z to the front
     #
     # The Male mean interpupillary distance is 64.7 mm (https://en.wikipedia.org/wiki/Interpupillary_distance)
     #
     '''
     
        P3D_RIGHT_SIDE = np.float32([-100.0, -77.5, -5.0]) #0
        P3D_GONION_RIGHT = np.float32([-110.0, -77.5, -85.0]) #4
        P3D_MENTON = np.float32([0.0, 0.0, -122.7]) #8
        P3D_GONION_LEFT = np.float32([-110.0, 77.5, -85.0]) #12
        P3D_LEFT_SIDE = np.float32([-100.0, 77.5, -5.0]) #16
        P3D_FRONTAL_BREADTH_RIGHT = np.float32([-20.0, -56.1, 10.0]) #17
        P3D_FRONTAL_BREADTH_LEFT = np.float32([-20.0, 56.1, 10.0]) #26
        P3D_SELLION = np.float32([0.0, 0.0, 0.0]) #27 This is the world origin
        P3D_NOSE = np.float32([21.1, 0.0, -48.0]) #30
        P3D_SUB_NOSE = np.float32([5.0, 0.0, -52.0]) #33
        P3D_RIGHT_EYE = np.float32([-20.0, -32.35,-5.0]) #36 
        P3D_RIGHT_TEAR = np.float32([-10.0, -20.25,-5.0]) #39
        P3D_LEFT_TEAR = np.float32([-10.0, 20.25,-5.0]) #42
        P3D_LEFT_EYE = np.float32([-20.0, 32.35,-5.0]) #45
        #P3D_LIP_RIGHT = np.float32([-20.0, 65.5,-5.0]) #48
        #P3D_LIP_LEFT = np.float32([-20.0, 65.5,-5.0]) #54
        P3D_STOMION = np.float32([10.0, 0.0, -75.0]) #62
     
     '''
 
     # This matrix contains the 3D points of the
     # 11 landmarks we want to find. It has been
     # obtained from antrophometric measurement
     # of the human head.
     '''
        landmarks_3D = np.float32([
            P3D_RIGHT_SIDE, P3D_GONION_RIGHT,
            P3D_MENTON,P3D_GONION_LEFT,
            P3D_LEFT_SIDE,P3D_FRONTAL_BREADTH_RIGHT,
            P3D_FRONTAL_BREADTH_LEFT,P3D_SELLION,
            P3D_NOSE,P3D_SUB_NOSE,P3D_RIGHT_EYE,
            P3D_RIGHT_TEAR,P3D_LEFT_TEAR,
            P3D_LEFT_EYE,P3D_STOMION])
    '''
    
    # Return the 2D position of our landmarks
    # img_h, img_w, img_d = image.shape
    # landmarks_2D = self._return_landmarks(inputImg=image, roiX=0, roiY=img_w, roiW=img_w, roiH=img_h, points_to_return=TRACKED_POINTS)
 
    # Read Image
    im = frame
    
    # Image dimensions in pixels
    size = im.shape
    
    # Landmark ID's for coordinate system reference points
    lm_nose, lm_leftMouth, lm_rightMouth = 30,64,60
    lm_chin, lm_leftEye, lm_rightEye = 8,46,37

    #2D image points. If you change the image, you need to change vector
    landmarks_2D = np.array(
    [
        (landmarks.part(lm_nose).x,       landmarks.part(lm_nose).y),       # Nose tip
        (landmarks.part(lm_chin).x,       landmarks.part(lm_chin).y),       # Chin
        (landmarks.part(lm_leftEye).x,    landmarks.part(lm_leftEye).y),    # Left eye left corner
        (landmarks.part(lm_rightEye).x,   landmarks.part(lm_rightEye).y),   # Right eye right corne
        (landmarks.part(lm_leftMouth).x,  landmarks.part(lm_leftMouth).y),  # Left Mouth corner
        (landmarks.part(lm_rightMouth).x, landmarks.part(lm_rightMouth).y)  # Right mouth corner
    ], 
        dtype="double")
     
    # 3D model points.
    landmarks_3D = np.array(
        [
            (-0.04173, -4.208,  22.90),     # Nose tip
            (-0.1188,  -16.88,  13.75),     # Chin
            (8.43,      1.469,  10.54),     # Left eye left corner
            (-8.394,    1.492,  10.56),     # Right eye right corner
            (3.916,    -10.32,  17.64),     # Left Mouth corner
            (-5.03,    -10.17,  17.64)      # Right mouth corner
        ]
    )
    
     # Print some red dots on the image       
     for point in landmarks_2D:
         cv2.circle(frame,( point[0], point[1] ), 2, (0,0,255), -1)
 
 
     # Applying the PnP solver to find the 3D pose
     # of the head from the 2D position of the
     # landmarks.
     # retval - bool
     # rvec - Output rotation vector that, together with tvec, brings 
     # points from the world coordinate system to the camera coordinate system.
     # tvec - Output translation vector. It is the position of the world origin (SELLION) in camera co-ords
     retval, rvec, tvec = cv2.solvePnP(
        landmarks_3D, landmarks_2D, self.camera_matrix, camera_distortion
        )
 
     # Get as input the rotational vector
     # Return a rotational matrix
     rmat, _ = cv2.Rodrigues(rvec) 
 
     # euler_angles contain (pitch, yaw, roll)
     # euler_angles = cv.DecomposeProjectionMatrix(projMatrix=rmat, cameraMatrix=camera_matrix, rotMatrix, transVect, rotMatrX=None, rotMatrY=None, rotMatrZ=None)
 
     head_pose = [ rmat[0,0], rmat[0,1], rmat[0,2], tvec[0],
                   rmat[1,0], rmat[1,1], rmat[1,2], tvec[1],
                   rmat[2,0], rmat[2,1], rmat[2,2], tvec[2],
                         0.0,      0.0,        0.0,    1.0 ]
     
     print(head_pose) #TODO remove this line
     return rotationMatrixToEulerAngles(rmat)


def headPoseEstimation(frame, landmarks):

    # Read Image
    im = frame
    
    # Image dimensions in pixels
    size = im.shape
    
    # Landmark ID's for coordinate system reference points
    lm_nose, lm_leftMouth, lm_rightMouth = 30,64,60
    lm_chin, lm_leftEye, lm_rightEye = 8,46,37

    #2D image points. If you change the image, you need to change vector
    image_points = np.array(
    [
        (landmarks.part(lm_nose).x,       landmarks.part(lm_nose).y),       # Nose tip
        (landmarks.part(lm_chin).x,       landmarks.part(lm_chin).y),       # Chin
        (landmarks.part(lm_leftEye).x,    landmarks.part(lm_leftEye).y),    # Left eye left corner
        (landmarks.part(lm_rightEye).x,   landmarks.part(lm_rightEye).y),   # Right eye right corne
        (landmarks.part(lm_leftMouth).x,  landmarks.part(lm_leftMouth).y),  # Left Mouth corner
        (landmarks.part(lm_rightMouth).x, landmarks.part(lm_rightMouth).y)  # Right mouth corner
    ], 
        dtype="double")
     
    # 3D model points.
    model_points = np.array(
        [
            (-0.04173, -4.208,  22.90),     # Nose tip
            (-0.1188,  -16.88,  13.75),     # Chin
            (8.43,      1.469,  10.54),     # Left eye left corner
            (-8.394,    1.492,  10.56),     # Right eye right corner
            (3.916,    -10.32,  17.64),     # Left Mouth corner
            (-5.03,    -10.17,  17.64)      # Right mouth corner
        ]
    )
    
    # Camera geometry
    focal_length = size[1]
    center = (size[1]/2, size[0]/2)
    
    # Camera Matrix
    camera_matrix = np.array(
    [
        [focal_length, 0, center[0]], 
        [0, focal_length, center[1]],
        [0, 0, 1]
    ], dtype = "double")     
    
    # Distances
    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion
    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)
    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 50.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)
     
    for p in image_points:
        cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)
     
    p1 = (int(image_points[0][0]), int(image_points[0][1]))
    p2 = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))
    
    cv2.line(im, p1, p2, (255,0,0), 2)
    cv2.putText(frame, "P1: "+str(p1)+"P2: "+str(p2), p1, font, .5, (255, 0, 0), 1, cv2.LINE_AA)
    
    print( "Vector [(p1: x, y), (p2: x, y)] for Euler Calculation", p1, p2 )
    print( "Camera Matrix :\n {0}".format(camera_matrix) )
    print( "Rotation Vector:\n {0}".format(rotation_vector) )
    print( "Translation Vector:\n {0}".format(translation_vector) )
    
    return frame, rotation_vector, translation_vector    
    

def reset_face():
    
    for i in range(min(_lm),max(_lm)+1): 
        if i in _lm:
            arm = bpy.data.objects["Armature.face"]         # Get Armature
            setMode("POSE")                                 # need POSE mode to set armature bones
            pb = arm.pose.bones["Bone."+str(i)]
                
            pb.location[0] = 0 # x
            pb.location[1] = 0 # y
            pb.location[2] = 0 # y

     # Get Armature
    arm = bpy.data.objects["Armature.neck"]
    
    # POSE mode allows translation
    setMode("POSE")                      
    
    # Get Bone
    targetBone = arm.pose.bones["cSpine"]  

    # Select Bone
    targetBone.bone.select=True 
    
    # Rotate the gead
    bpy.ops.transform.trackball(
        value=(0,0), mirror=True, use_proportional_edit=False,
        proportional_edit_falloff='SMOOTH', proportional_size=1, 
        use_proportional_connected=False, 
        use_proportional_projected=False, 
        release_confirm=True
        )
    
    # X Axis
    bpy.ops.transform.rotate(value=0.00, orient_axis='X', orient_type='GLOBAL', orient_matrix=((1, 0, 0), (0, 1, 0), (0, 0, 1)), orient_matrix_type='GLOBAL', constraint_axis=(False, False, True), mirror=True, use_proportional_edit=False, proportional_edit_falloff='SMOOTH', proportional_size=1, use_proportional_connected=False, use_proportional_projected=False, release_confirm=True)
    
    # Y Axis
    bpy.ops.transform.rotate(value=0.00, orient_axis='Y', orient_type='GLOBAL', orient_matrix=((1, 0, 0), (0, 1, 0), (0, 0, 1)), orient_matrix_type='GLOBAL', constraint_axis=(False, False, True), mirror=True, use_proportional_edit=False, proportional_edit_falloff='SMOOTH', proportional_size=1, use_proportional_connected=False, use_proportional_projected=False, release_confirm=True)    

    # Z Axis
    bpy.ops.transform.rotate(value=0.00, orient_axis='Z', orient_type='GLOBAL', orient_matrix=((1, 0, 0), (0, 1, 0), (0, 0, 1)), orient_matrix_type='GLOBAL', constraint_axis=(False, False, True), mirror=True, use_proportional_edit=False, proportional_edit_falloff='SMOOTH', proportional_size=1, use_proportional_connected=False, use_proportional_projected=False, release_confirm=True)
    
    print("Reset Face and Head")

    # Redraw the 3d view
    bpy.ops.wm.redraw_timer(type='DRAW_WIN_SWAP', iterations=1) # Refresh 3D View

    return True


############################# Execution #############################

# begin the animation
animate(cycles=200)
reset_face()